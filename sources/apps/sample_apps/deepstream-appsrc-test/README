*****************************************************************************
* Copyright (c) 2020-2022 NVIDIA Corporation.  All rights reserved.
*
* NVIDIA Corporation and its licensors retain all intellectual property
* and proprietary rights in and to this software, related documentation
* and any modifications thereto.  Any use, reproduction, disclosure or
* distribution of this software and related documentation without an express
* license agreement from NVIDIA Corporation is strictly prohibited.
*****************************************************************************

*****************************************************************************
                     deepstream-appsrc-test
                             README
*****************************************************************************

===============================================================================
1. Prerequisites:
===============================================================================

Please follow instructions in the apps/sample_apps/deepstream-app/README on how
to install the prequisites for Deepstream SDK, the DeepStream SDK itself and the
apps.

You must have the following development packages installed
    GStreamer-1.0
    GStreamer-1.0 Base Plugins
    GStreamer-1.0 gstrtspserver
    X11 client-side library

To install these packages, execute the following command:
   sudo apt-get install libgstreamer-plugins-base1.0-dev libgstreamer1.0-dev \
   libgstrtspserver-1.0-dev libx11-dev

===============================================================================
2. Purpose:
===============================================================================

This document shall describe about the sample deepstream-appsrc-test application.

It is meant to demonstrate how raw video frames acquired from outside DeepStream
can be fed to a DeepStream pipeline. It also demostrates how metadata can be accessed
via appsink and used outside deepstream.

===============================================================================
3. To compile:
===============================================================================

  $ Set CUDA_VER in the MakeFile as per platform.
      For Jetson, CUDA_VER=11.4
      For x86, CUDA_VER=11.6
  $ sudo make


===============================================================================
4. Usage:
===============================================================================

Creating raw video streams from Encoded streams:
Raw streams can be created using gst-launch-1.0. The pipeline is as follows:
  $ gst-launch-1.0 uridecodebin uri=<URI of file> ! nvvideoconvert !
      'video/x-raw, format=<Format of stream (example: I420, NV12, RGBA)>,
      width=<Width of stream>, height=<height of stream>' ! filesink location=test.raw

Ensure the directory where raw file needs to be saved has write permissions.
i.e. /opt/nvidia/deepstream/deepstream/samples/streams/ needs write permissions before executing
below sample pipeline.

  $ gst-launch-1.0 uridecodebin \
      uri=file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_720p.mp4 \
      ! nvvideoconvert ! 'video/x-raw, format=I420, width=1280, height=720' \
      ! filesink location= /opt/nvidia/deepstream/deepstream/samples/streams/sample_720p.i420

To run the application with raw video stream:
  $ ./deepstream-appsrc-test <Raw video stream (example: YUV)> <width of stream>
      <height of stream> <expected FPS of stream> <format of stream (example: I420, NV12, RGBA)>
  e.g.
  $ ./deepstream-appsrc-test /opt/nvidia/deepstream/deepstream/samples/streams/sample_720p.i420 1280 720 30 I420

This sample uses appsrc APIs to push raw video frames read using fread () onto appsrc
component. From appsrc, the usual deepstream components are then used. Single primary
inferencing is used here. Then the buffers are sent via a tee to regular video rendering sink and
appsink. Appsink extracts buffer from sample and then obtains metadata information from it.

NOTE: This app supports only RGBA, NV12 and I420 raw video streams.

