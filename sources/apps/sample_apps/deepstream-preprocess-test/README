*****************************************************************************
* Copyright (c) 2021-2022 NVIDIA Corporation.  All rights reserved.
*
* NVIDIA Corporation and its licensors retain all intellectual property
* and proprietary rights in and to this software, related documentation
* and any modifications thereto.  Any use, reproduction, disclosure or
* distribution of this software and related documentation without an express
* license agreement from NVIDIA Corporation is strictly prohibited.
*****************************************************************************

*****************************************************************************
                     deepstream-preprocess-test
                             README
*****************************************************************************

===============================================================================
1. Prerequisites:
===============================================================================

Please follow instructions in the apps/sample_apps/deepstream-app/README on how
to install the prerequisites for the Deepstream SDK, the DeepStream SDK itself,
and the apps.

You must have the following development packages installed
   GStreamer-1.0
   GStreamer-1.0 Base Plugins
   GStreamer-1.0 gstrtspserver
   X11 client-side library

To install these packages, execute the following command:
   sudo apt-get install libgstreamer-plugins-base1.0-dev libgstreamer1.0-dev \
   libgstrtspserver-1.0-dev libx11-dev

===============================================================================
2. Purpose:
===============================================================================

This sample app builds on top of the deepstream-test3 sample app to demonstrate
how to:

* Use multiple sources in the pipeline.
* Use a uridecodebin so that any type of input (e.g. RTSP/File), any GStreamer
  supported container format, and any codec can be used as input.
* Configure the stream-muxer to generate a batch of frames and infer on the
  batch for better resource utilization.
* Extract the stream metadata, which contains useful information about the
  frames in the batched buffer.
* Per group custom preprocessing on ROIs provided
* Prepares raw tensor for inferencing
* nvinfer skips preprocessing and infer from input tensor meta

===============================================================================
3. To compile:
===============================================================================

  $ Set CUDA_VER in the MakeFile as per platform.
      For Jetson, CUDA_VER=11.4
      For x86, CUDA_VER=11.6

  $ cd /opt/nvidia/deepstream/deepstream/sources/gst-plugins/gst-nvdspreprocess
  $ sudo make && sudo make install

  $ cd /opt/nvidia/deepstream/deepstream/sources/gst-plugins/gst-nvdspreprocess/nvdspreprocess_lib
  $ sudo make && sudo make install

  $ cd /opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-preprocess-test
  $ sudo make && sudo make install

NOTE: To compile the sources, run make with "sudo" or root permission.

===============================================================================
4. Usage:
===============================================================================

  $ ./deepstream-preprocess-test <nvdspreprocess-config-file> <nvinfer-config-file> [uri1] [uri2] ... [uriN]
e.g.
  $ ./deepstream-preprocess-test config_preprocess.txt config_infer.txt file:///video1.mp4 file:///video2.mp4
  $ ./deepstream-preprocess-test config_preprocess.txt config_infer.txt rtsp://127.0.0.1/video1 rtsp://127.0.0.1/video2

NOTE:
1. For optimal performance, set nvinfer batch-size in nvinfer config file same as
   preprocess batch-size (network-input-shape[0]) in nvdspreprocess config file.
2. Currently preprocessing only for primary gie has been supported.
3. Modify config_preprocess.txt for as per use case.

Refer to the deepstream-test3 sample documentation for an example of simple
multi-stream inference, bounding-box overlay, and rendering.

This sample accepts one or more H.264/H.265 video streams as input. It creates
a source bin for each input and connects the bins to an instance of the
"nvstreammux" element, which forms the batch of frames.

Then, "nvdspreprocess" plugin preprocessed the batched frames and prepares a raw
tensor for inferencing, which is attached as user meta at batch level. User can
provide custom preprocessing library having custom per group transformation
functions and custom tensor preparation function.

Then, "nvinfer" uses the preprocessed raw tensor from meta data for batched
inferencing. The batched buffer is composited into a 2D tile array using
"nvmultistreamtiler."

The rest of the pipeline is similar to the deepstream-test3 sample.

NOTE: To reuse engine files generated in previous runs, update the
model-engine-file parameter in the nvinfer config file to an existing engine file
